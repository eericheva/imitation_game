{
    "host": "0.0.0.0",
    "port": 8080,
    "models": [
        {
            "model": "data/second-state/Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf",
            "model_alias": "ImitationGameLlamaCPP",
            "n_threads": 12,
            "n_ctx": 0,
            "use_mlock": "true",
            "flash_attn": "true",
            "verbose": "false"
        }
    ]
}
